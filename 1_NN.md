# [1_NN.py](./1_NN.py)
## 1.2 [全连接网络](./1_NN.py#L36)
&emsp;&emsp;终于，今天把《动手学深度学习(PyTorch版)》中与本次算法题相关的部分简单过了一遍。第一题有点不明所以，一会查一下资料。先看全连接这题吧，感觉还是比较基础的。

首先从线性神经网络说起，以一元线性回归模型为例：

$$\begin{cases}y=ax+b+\epsilon \newline \epsilon \sim N(0,\sigma^2)\end{cases}$$

&emsp;&emsp;可以通过线性回归建立从特征到标签的线性模型。但是，特征与标签间往往不是简单的线性关系。因此，我们引入激活函数，如sigmoid，tanh，以及relu等，使多个线性关系叠加，就如同泰勒展开、傅里叶分解一般，能够将复杂的关系用最基本的关系去逼近。

&emsp;&emsp;此全连接层/多层感知机大概干的便是这么一件事：后面的层对前面所有层进行分型叠加。那么中间的层就可以视为元数据中蕴含的某种模式Pattern。类似噪波叠加octave。如果叠加层数太少，那么便显得单调空洞，但若叠加层数太多，又会显得杂乱。

![](./img/octave.png)

&emsp;&emsp;因此，中间隐藏层的增加很有必要，且层数也很关键。

## 1.1 [基本评测指标](./1_NN.py#L98)

> 多分类问题的基本评估指标包括：
> 
> 1. **准确率（Accuracy）：** 准确率是分类器正确分类的样本数量与总样本数量的比率。它是最常见的评估指标之一，但在类别不平衡的情况下可能不够准确。计算公式为：$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$。
> 
> 2. **精确率（Precision）：** 精确率是指被分类器正确预测为某一类别的样本数量与分类器所有预测为该类别的样本数量之比。计算公式为：$Precision = \frac{TP}{TP + FP}$。
> 
> 3. **召回率（Recall）：** 召回率是指被分类器正确预测为某一类别的样本数量与该类别在总样本中的数量之比。计算公式为：$Recall = \frac{TP}{TP + FN}$。
> 
> 4. **F1 分数（F1-Score）：** F1 分数是精确率和召回率的调和平均数，它综合考虑了精确率和召回率的性能。计算公式为：$F1 = \frac{2 \times Precision * Recall}{Precision + Recall}$。
> 

以上指标可借助混淆矩阵计算。

对于二分类问题，混淆矩阵为：
|          |预测正例 | 预测反例
-|-|-|
真实正例  | TP    |   FN
真实反例  | FP    |    TN

对于多分类问题，比较容易困惑的点是假正例（FP）和假反例（FN）如何计算。以3分类问题为例，假设其混淆矩阵如下：

|   |  预测A  |  预测B  |  预测C  |
-|:--:|:--:|:--:|
真实A   |  15 |  2  |  3  |
真实B   |  1  |  18 |  2  |
真实C   |  3  |  1  |  20 |

那么，对于A来说，什么是假？从逻辑上说，非真即是假，即对A来说，B、C为假。因此，对于`单个`类别，其混淆矩阵为：

|     |正     | 非正 | 非正 
-|-      |-     |-     
真    | TP    |   FN |   FN 
非真  | FP    |    TN|    TN
非真  | FP    |    TN|    TN

通过计算每个类别的指标，然后对所有类别的相应指标取平均值，即为总体的指标。此时可以取等权平均或者`加权平均`。等权平均对所有类别一视同仁，而加权平均会更加重视样本占比较高的类别。

例如，某一分类出现频率极低，往往造成异常数据导致precision过低，若与其他类别等权平均，则会导致总体的precision偏低，此时，采用加权平均会使结果更真实。

本题中，若评估模型在整个数据集上的平均性能，那么可以选择加权平均。